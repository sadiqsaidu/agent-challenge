# .env.example

# --- Toggle between AI providers ---
# Set to 'google' for Google Gemini, or 'qwen' for Qwen via Ollama/Nosana.
AI_PROVIDER=google

# --- Google Gemini API Key (only used if AI_PROVIDER=google) ---
# Get your API key from Google AI Studio: https://aistudio.google.com/
GOOGLE_GENERATIVE_AI_API_KEY="your_google_gemini_api_key_here"

# --- Qwen via Nosana Gateway / Local Ollama (only used if AI_PROVIDER=qwen) ---
# For Nosana: Get your endpoint from the Nosana Dashboard.
# ⚠️ Ensure it ends with /v1 if required by the SDK, NOT /api or /api/v1 (check Nosana docs).
# For local Ollama: Use http://localhost:11434/v1
API_BASE_URL=https://your-nosana-endpoint/v1
MODEL_NAME_AT_ENDPOINT=qwen2.5:7b # Or qwen2.5:1.5b for lighter local testing
QWEN_API_KEY=dummy   # Placeholder; might be needed by the SDK but actual value varies by endpoint

# --- Tool API Keys (needed by helpers.ts) ---
# Alchemy for Solana blockchain data: https://www.alchemy.com/
ALCHEMY_API_KEY=your_alchemy_api_key_here
# CryptoCompare for cryptocurrency market data: https://www.cryptocompare.com/
CRYPTOCOMPARE_API_KEY=your_cryptocompare_api_key_here
# NewsAPI for news articles: https://newsapi.org/
NEWS_API_KEY=your_newsapi_key_here

# --- Mastra / Runtime Settings ---
# Set to 'dev' for local development with the Mastra Playground UI.
# Set to 'prod' for production deployment (e.g., on Nosana).
MASTRA_MODE=dev # or prod for deployment
# Set the logging level (e.g., 'info', 'debug', 'warn', 'error').
MASTRA_LOG_LEVEL=info
# The port your application listens on.
PORT=8080